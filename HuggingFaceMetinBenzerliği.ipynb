{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0398c444-4a93-44b3-851b-ec3ce43379fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metin benzerliği skoru: 0.9611722826957703\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Önceden eğitilmiş bir benzerlik modelini yükle\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Karşılaştırılacak metinleri tanımlayın\n",
    "text1 = \"Bu bir örnek cümle.\"\n",
    "text2 = \"Bu bir başka örnek cümle.\"\n",
    "\n",
    "# Her iki metni önce modelden geçirin\n",
    "inputs1 = tokenizer(text1, return_tensors=\"pt\")\n",
    "inputs2 = tokenizer(text2, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs1 = model(**inputs1).last_hidden_state.mean(dim=1).squeeze()\n",
    "    outputs2 = model(**inputs2).last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "# Cosine benzerliğini hesapla\n",
    "similarity_score = 1 - cosine(outputs1, outputs2)\n",
    "\n",
    "print(f\"Metin benzerliği skoru: {similarity_score.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcb793cd-06cb-438a-9644-18ff21e137d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metin benzerliği skoru: 0.7751219272613525\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Önceden eğitilmiş bir benzerlik modelini yükle\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Karşılaştırılacak metinleri tanımlayın\n",
    "text1 = \"Hava durumu bugün çok güzel.\"\n",
    "text2 = \"Yarın yağmur bekleniyor.\"\n",
    "\n",
    "# Her iki metni önce modelden geçirin\n",
    "inputs1 = tokenizer(text1, return_tensors=\"pt\")\n",
    "inputs2 = tokenizer(text2, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs1 = model(**inputs1).last_hidden_state.mean(dim=1).squeeze()\n",
    "    outputs2 = model(**inputs2).last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "# Cosine benzerliğini hesapla\n",
    "similarity_score = 1 - cosine(outputs1, outputs2)\n",
    "\n",
    "print(f\"Metin benzerliği skoru: {similarity_score.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46181396-54cd-44d8-a181-125546ff4589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metin benzerliği skoru: 0.9904300570487976\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Önceden eğitilmiş bir benzerlik modelini yükle\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Karşılaştırılacak uzun metinleri tanımlayın\n",
    "text1 = \"Bu uzun bir metin örneğidir ve BERT modeli tarafından işlenebilmesi için token sınırlamasına uygun hale getirilmiştir. \"\n",
    "text2 = \"Bu da diğer bir uzun metin örneğidir ve BERT modeli ile benzerlik ölçümü yapılabilmesi için token sınırlamasına uygun hale getirilmiştir.\"\n",
    "\n",
    "# Her iki metni önce modelden geçirin\n",
    "inputs1 = tokenizer(text1, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "inputs2 = tokenizer(text2, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs1 = model(**inputs1).last_hidden_state.mean(dim=1).squeeze()\n",
    "    outputs2 = model(**inputs2).last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "# Cosine benzerliğini hesapla\n",
    "similarity_score = 1 - cosine(outputs1, outputs2)\n",
    "\n",
    "print(f\"Metin benzerliği skoru: {similarity_score.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "737ec322-6c10-4fa3-8495-5de6256e9e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelime benzerliği skoru: 0.9063009023666382\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Önceden eğitilmiş bir kelime gömme modelini yükle\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Analiz için kelimeleri tanımla\n",
    "word1 = \"happiness\"\n",
    "word2 = \"sadness\"\n",
    "\n",
    "# Her iki kelimeyi önce modelden geçir\n",
    "input_ids1 = tokenizer(word1, return_tensors=\"pt\")[\"input_ids\"]\n",
    "input_ids2 = tokenizer(word2, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    #Her metin için last_hidden_state çıktısı alınır, bu çıktıdan ortalamayı alır ve gereksiz boyutları sıkıştırır (squeeze). Bu adımlar sonucunda her metin için bir temsil vektörü elde edilir.\n",
    "    embeddings1 = model(input_ids1).last_hidden_state.mean(dim=1).squeeze() \n",
    "    embeddings2 = model(input_ids2).last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "# Cosine benzerliğini hesapla\n",
    "similarity_score = 1 - cosine(embeddings1, embeddings2)\n",
    "\n",
    "print(f\"Kelime benzerliği skoru: {similarity_score.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ecff0-65a3-415f-8ffc-3c98c3f44187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
