{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8278c931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is an example document.', 'It has two sentences.', 'This document has one sentence and an emoticon.', 'Here is another example document.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "cumleler = [\"This is an example document. It has two sentences.\",\n",
    "            \"This document has one sentence and an emoticon. :)\",\n",
    "            \"Here is another example document. :D\",\n",
    "           \"Merhaba bugün hava yağmurlu.\"]\n",
    "\n",
    "tokenlar = [sent_tokenize(cumle) for cumle in cumleler]\n",
    "\n",
    "ifade=\"This is an example document. It has two sentences. This document has one sentence and an emoticon. Here is another example document. \"\n",
    "print(sent_tokenize(ifade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8de3d7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['This is an example document.', 'It has two sentences.'],\n",
       " ['This document has one sentence and an emoticon.', ':)'],\n",
       " ['Here is another example document.', ':D'],\n",
       " ['Merhaba bugün hava yağmurlu.']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f203eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════════╤═══════════════╤═══════════════════╤════════════════════╤═══════════════════╤════════════╕\n",
      "│                  │               │                   │                    │ Token             │ POS Tag    │\n",
      "╞══════════════════╪═══════════════╪═══════════════════╪════════════════════╪═══════════════════╪════════════╡\n",
      "│ Ahmet            │ ile           │ Mehmet            │ sinemaya           │ gidecek           │ .          │\n",
      "├──────────────────┼───────────────┼───────────────────┼────────────────────┼───────────────────┼────────────┤\n",
      "│ ('Ahmet', 'NNP') │ ('ile', 'NN') │ ('Mehmet', 'NNP') │ ('sinemaya', 'NN') │ ('gidecek', 'NN') │ ('.', '.') │\n",
      "╘══════════════════╧═══════════════╧═══════════════════╧════════════════════╧═══════════════════╧════════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Kaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from tabulate import tabulate\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Önce nltk'nin gerekli kaynaklarını indirin\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Verilen metin\n",
    "cumleler = [\"This is an example document. It has two sentences.\",\n",
    "            \"This document has one sentence and an emoticon. :)\",\n",
    "            \"Here is another example document.\",\n",
    "           \"Ahmet ile Mehmet sinemaya gidecek.\"]\n",
    "\n",
    "# Cümleleri tokenleştir\n",
    "tokenlar = [word_tokenize(cumle) for cumle in cumleler]\n",
    "\n",
    "# Token detaylarını al\n",
    "token_ayrinti = [(token, nltk.pos_tag(token)) for token in tokenlar]\n",
    "\n",
    "# Token detaylarını tablo olarak göster\n",
    "print(tabulate(token_ayrinti[3], headers=['Token', 'POS Tag'], tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "889281ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Duydum', 'ki', 'bizi', 'bırakmaya', 'azmediyorsun', ',', 'etme', '.'], ['Başka', 'bir', 'yar', ',', 'başka', 'bir', 'dosta', 'meylediyorsun', ',', 'etme', '.'], ['Sen', 'yadeller', 'dünyasında', 'ne', 'arıyorsun', 'yabancı', '?'], ['Hangi', 'hasta', 'gönüllüyü', 'kastediyorsun', ',', 'etme', '.'], ['Çalma', 'bizi', ',', 'bizden', 'bizi', ',', 'gitme', 'o', 'ellere', 'doğru', '.'], ['Çalınmış', 'başkalarına', 'nazar', 'ediyorsun', ',', 'etme', '.'], ['Ey', 'ay', ',', 'felek', 'harab', 'olmuş', ',', 'altüst', 'olmuş', 'senin', 'için', '...'], ['Bizi', 'öyle', 'harab', ',', 'öyle', 'altüst', 'ediyorsun', ',', 'etme', '.'], ['Ey', ',', 'makamı', 'var', 've', 'yokun', 'üzerinde', 'olan', 'kişi', ','], ['Sen', 'varlık', 'sahasını', 'öyle', 'terk', 'ediyorsun', ',', 'etme', '.'], ['Sen', 'yüz', 'çevirecek', 'olsan', ',', 'ay', 'kapkara', 'olur', 'gamdan', '.'], ['Ayın', 'da', 'evini', 'yıkmayı', 'kastediyorsun', ',', 'etme', '.'], ['Bizim', 'dudağımız', 'kurur', 'sen', 'kuruyacak', 'olsan', '.'], ['Gözlerimizi', 'öyle', 'yaş', 'dolu', 'ediyorsun', ',', 'etme', '.'], ['Aşıklarla', 'başa', 'çıkacak', 'gücün', 'yoksa', 'eğer', ';'], ['Aşka', 'öyleyse', 'ne', 'diye', 'hayret', 'ediyorsun', ',', 'etme', '.'], ['Ey', ',', 'cennetin', 'cehennemin', 'elinde', 'oldugu', 'kişi', ','], ['Bize', 'cenneti', 'öyle', 'cehennem', 'ediyorsun', ',', 'etme', '.'], ['Şekerliğinin', 'içinde', 'zehir', 'zarar', 'vermez', 'bize', ','], ['O', 'zehiri', 'o', 'şekerle', 'sen', 'bir', 'ediyorsun', ',', 'etme', '.'], ['Bizi', 'sevindiriyorsun', ',', 'huzurumuz', 'kaçar', 'öyle', '.'], ['Huzurumu', 'bozuyorsun', ',', 'sen', 'mahvediyorsun', ',', 'etme', '.'], ['Harama', 'bulaşan', 'gözüm', ',', 'güzelliğinin', 'hırsızı', '.'], ['Ey', 'hırsızlığa', 'da', 'değen', 'hırsızlık', 'ediyorsun', ',', 'etme', '.'], ['İsyan', 'et', 'ey', 'arkadaşım', ',', 'söz', 'söyleyecek', 'an', 'değil', '.'], ['Aşkın', 'baygınlığıyla', 'ne', 'meşk', 'ediyorsun', ',', 'etme', '.']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Önce nltk'nin gerekli kaynaklarını indirin\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Dosya adı\n",
    "dosya = \"mevlana.txt\"\n",
    "\n",
    "# Dosyadan metni al\n",
    "with open(dosya, 'r', encoding='utf-8') as file:\n",
    "    str_metin = file.read()\n",
    "\n",
    "# Metni satırlara böl\n",
    "textData = str_metin.split('\\n')\n",
    "\n",
    "# Cümleleri tokenleştir\n",
    "tokenlar = [word_tokenize(cumle) for cumle in textData]\n",
    "\n",
    "\n",
    "print(tokenlar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f51060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
