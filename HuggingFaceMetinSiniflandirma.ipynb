{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c46f651a-d98b-488e-a7cf-629aef028357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# D1.txt dosyasından spam mesajlarını oku\n",
    "with open('spam/D1.txt', 'r', encoding='utf-8') as file:\n",
    "    d1_data = file.readlines()\n",
    "\n",
    "# D2.txt dosyasından etiket isimlerini oku\n",
    "with open('spam/D2.txt', 'r', encoding='utf-8') as file:\n",
    "    d2_data = file.readlines()\n",
    "\n",
    "# Etiket isimlerini 0 (ham) veya 1 (spam) olarak dönüştür\n",
    "labels = [0 if label.strip() == 'spam' else 1 for label in d2_data]\n",
    "\n",
    "# Yeni DataFrame'i oluştur\n",
    "df = pd.DataFrame({'Mesaj': d1_data, 'Etiket': labels})\n",
    "\n",
    "# Oluşturulan DataFrame'i spam.xlsx dosyasına kaydet\n",
    "df.to_excel('spam.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7623705-c038-45cb-b579-b67480aab1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Mesaj  Etiket  Spam Tahmini  \\\n",
      "0     Urgent!call09061749602fromLandlineYourcomplime...       0             1   \n",
      "1     449071512431URGENT!Thisisthe2ndattempttocontac...       0             0   \n",
      "2     FREEfor1stweek!No1Nokiatone4urmobeveryweekjust...       0             1   \n",
      "3     Urgent!call09066612661fromlandlineYourcompleme...       0             1   \n",
      "4     WINNER!!Asavaluednetworkcustomeryouhavebeensel...       0             0   \n",
      "...                                                 ...     ...           ...   \n",
      "1319  GreatNews!CallFREEFONE08006344447toclaimyourgu...       0             1   \n",
      "1320  YouhaveWONaguaranteed�1000cashora�2000prizeToc...       0             0   \n",
      "1321                 08714712388between10am7pmCost10p\\n       0             1   \n",
      "1322  YES!Theonlyplaceintowntomeetexcitingadultsingl...       0             1   \n",
      "1323  CongratulationsThankstoagoodfriendUhaveWONthe�...       0             0   \n",
      "\n",
      "      Spam Skoru  \n",
      "0       0.507322  \n",
      "1       0.504368  \n",
      "2       0.510511  \n",
      "3       0.503846  \n",
      "4       0.503261  \n",
      "...          ...  \n",
      "1319    0.503460  \n",
      "1320    0.502171  \n",
      "1321    0.524329  \n",
      "1322    0.502754  \n",
      "1323    0.504259  \n",
      "\n",
      "[1324 rows x 4 columns]\n",
      "\n",
      "Spam Sınıflandırma Başarı Oranı: 70.69%\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# DistilBERT modelini yükle\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,from_tf=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Metin sınıflandırma pipeline'ini oluştur\n",
    "classifier_pipeline = pipeline('text-classification', model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# spam.xlsx dosyasından veriyi oku\n",
    "df = pd.read_excel('spam.xlsx')\n",
    "\n",
    "\n",
    "# Verileri sınıflandır ve sonuçları DataFrame'e ekle\n",
    "results = classifier_pipeline(df['Mesaj'].tolist())\n",
    "df['Spam Tahmini'] = [int(result['label'].split('_')[-1]) for result in results]  \n",
    "df['Spam Skoru'] = [result['score'] for result in results]\n",
    "\n",
    "# Başarı oranını hesapla\n",
    "correct_predictions = df[df['Etiket'] == df['Spam Tahmini']].shape[0]\n",
    "total_samples = df.shape[0]\n",
    "accuracy = correct_predictions / total_samples * 100\n",
    "\n",
    "# DataFrame'i ekrana yazdır\n",
    "print(df[['Mesaj', 'Etiket', 'Spam Tahmini', 'Spam Skoru']])\n",
    "print(f\"\\nSpam Sınıflandırma Başarı Oranı: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36922b4-e33c-47f3-bbe2-4b74cff7c7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edccc2c5-88fb-480a-bff1-40949b0431d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Kaya\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitim Bölümü\n",
      "Test Bölümü\n",
      "Test Accuracy: 94.47%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Veri kümesini yükleyin\n",
    "df = pd.read_excel('spam.xlsx')\n",
    "\n",
    "# Veri kümesini eğitim ve test olarak bölün\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Tokenizer ve modeli yükleyin\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)  # 2 sınıf var: spam ve ham\n",
    "\n",
    "# Verileri tokenleştirin ve DataLoader oluşturun\n",
    "def tokenize_data(data, tokenizer, max_length=128):\n",
    "    tokenized_data = tokenizer(data['Mesaj'].tolist(), truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
    "    labels = torch.tensor(data['Etiket'].tolist())\n",
    "    return TensorDataset(tokenized_data['input_ids'], tokenized_data['attention_mask'], labels)\n",
    "\n",
    "train_dataset = tokenize_data(train_df, tokenizer)\n",
    "test_dataset = tokenize_data(test_df, tokenizer)\n",
    "\n",
    "# DataLoader'ları oluşturun\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Modeli eğitin\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "epochs = 3\n",
    "print(\"Eğitim Bölümü\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, attention_mask, labels = batch\n",
    "        outputs = model(inputs, attention_mask=attention_mask)[0]\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Modelin performansını test edin\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "print(\"Test Bölümü\")\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, attention_mask, labels = batch\n",
    "        outputs = model(inputs, attention_mask=attention_mask)[0]\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5acff9a-8c30-4883-aa07-8cd2c1355055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
