{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c58fbb70-e2ec-4165-b481-10f5490725cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7, 30, 31, 4, 7, 32, 33, 34, 35, 36, 12, 37, 38, 39, 12, 40, 41, 42, 43, 44, 45, 46, 47, 48, 2, 49, 5, 50, 51, 8, 52, 53, 54, 55, 56, 57, 6, 58, 59, 60, 61, 62, 63, 64, 65, 66, 13, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 14, 3, 77, 14, 78, 79, 80, 81, 3, 82, 83, 84, 85, 86, 9, 87, 88, 1, 89, 90, 91, 92, 2, 93, 94, 95, 15, 1, 16, 96, 17, 97, 98, 6, 99, 5, 100, 101, 5, 102, 103, 104, 105, 106, 107, 108, 109, 18, 8, 110, 111, 112, 113, 2, 114, 115, 13, 116, 117, 118, 6, 119, 120, 121, 122, 123, 10, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 6, 135, 136, 137, 138, 11, 139, 140, 141, 3, 142, 143, 18, 8, 19, 144, 145, 10, 1, 146, 16, 147, 148, 149, 150, 151, 2, 152, 153, 1, 154, 155, 156, 17, 20, 157, 158, 21, 159, 160, 161, 162, 163, 22, 23, 164, 165, 22, 23, 166, 167, 168, 3, 9, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 9, 179, 180, 181, 11, 182, 183, 184, 21, 185, 186, 187, 188, 189, 3, 190, 191, 11, 1, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 1, 202, 203, 204, 205, 206, 24, 2, 25, 207, 208, 209, 210, 211, 212, 213, 214, 215, 26, 216, 217, 218, 24, 219, 220, 221, 222, 223, 25, 224, 20, 26, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 5, 251, 252, 253, 254, 15, 4, 255, 19, 256, 257, 258, 27, 259, 260, 261, 262, 263, 264, 4, 7, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 27, 278, 279, 280, 28, 29, 281, 282, 283, 284, 285, 29, 286, 287, 288, 28, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 10, 303, 304, 305, 306, 307, 308]\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 6s 214ms/step - loss: 5.7359\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 3s 241ms/step - loss: 5.7263\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 5.7166\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 3s 246ms/step - loss: 5.6855\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 4s 353ms/step - loss: 5.6426\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 5.5418\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 3s 231ms/step - loss: 5.3936\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 3s 218ms/step - loss: 5.2489\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 3s 231ms/step - loss: 5.0868\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 3s 279ms/step - loss: 4.9481\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 3s 241ms/step - loss: 4.8353\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 3s 232ms/step - loss: 4.8341\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 3s 255ms/step - loss: 4.5849\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 3s 217ms/step - loss: 4.4494\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 3s 256ms/step - loss: 4.3193\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 3s 240ms/step - loss: 4.1988\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 3s 240ms/step - loss: 4.0757\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 3s 240ms/step - loss: 3.9636\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 2s 197ms/step - loss: 3.8530\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 3s 222ms/step - loss: 3.7415\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 3.6401\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 3s 254ms/step - loss: 3.5349\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 3s 231ms/step - loss: 3.4562\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 3s 217ms/step - loss: 3.3576\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 3s 221ms/step - loss: 3.2800\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 3s 218ms/step - loss: 3.2142\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 3.1388\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 3s 256ms/step - loss: 3.0600\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 3s 237ms/step - loss: 2.9856\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 3s 254ms/step - loss: 2.9261\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 3s 214ms/step - loss: 2.8601\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 3s 246ms/step - loss: 2.8127\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 3s 244ms/step - loss: 2.7740\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 3s 217ms/step - loss: 2.7241\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 2s 209ms/step - loss: 2.6795\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 3s 241ms/step - loss: 2.6376\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 2.5804\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 4s 348ms/step - loss: 2.5530\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2.5213\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 2.4930\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 2s 205ms/step - loss: 2.4494\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 2.4143\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 4s 295ms/step - loss: 2.3931\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 4s 342ms/step - loss: 2.3599\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 4s 337ms/step - loss: 2.3260\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 3s 275ms/step - loss: 2.3048\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 3s 246ms/step - loss: 2.2724\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 3s 292ms/step - loss: 2.2395\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 3s 249ms/step - loss: 2.2199\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 2s 204ms/step - loss: 2.2012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c653819c90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "import keras.utils\n",
    "\n",
    "# Dosyadan metni okuma\n",
    "with open(\"roman2.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Metni kelimelere ayırma\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Metni sayılara çevirme\n",
    "sequences = tokenizer.texts_to_sequences([text])[0]\n",
    "print(sequences)\n",
    "\n",
    "# Giriş ve çıkış oluşturma\n",
    "input_sequences = []\n",
    "for i in range(1, len(sequences)):\n",
    "    n_gram_sequence = sequences[:i+1]\n",
    "    input_sequences.append(n_gram_sequence)\n",
    "\n",
    "maxlen = max([len(seq) for seq in input_sequences])\n",
    "\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=maxlen, padding='pre')  \n",
    "x, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y = keras.utils.to_categorical(y, num_classes=total_words)\n",
    "\n",
    "# LSTM modeli oluşturma\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 50, input_length=maxlen-1))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "model.fit(x, y, epochs=50, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e565e09-4bac-4139-813a-410b302a0579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Üstündeki  kemal kemal kemal kemal kemal kemal kemal kemal kemal kemal kemal kemal kemal köyünde köyünde\n"
     ]
    }
   ],
   "source": [
    "# Örnek metin üretimi\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        # token_list'e bir kelime daha ekledik\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "        predicted = np.argmax(predicted_probs)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Örnek metin üretimi\n",
    "generated_text = generate_text(\"Üstündeki \", 15, model, max_sequence_len=maxlen-1)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f365b51-a8c6-41a4-821b-1aecab5c156b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   0   4   7]\n",
      " [  0   0   0 ...   4   7  30]\n",
      " [  0   0   0 ...   7  30  31]\n",
      " ...\n",
      " [  0   0   4 ... 304 305 306]\n",
      " [  0   4   7 ... 305 306 307]\n",
      " [  4   7  30 ... 306 307 308]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ef340a-9114-4701-a104-efa338c8eabd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
